{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process BAST traffic count data\n",
    "Source: https://www.bast.de/BASt_2017/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/zaehl_node.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "import requests\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for download \n",
    "Functions for download and unzip BAST hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual downloading\n",
    "def download_url(url, save_path):\n",
    "    #function from: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url/14260592\n",
    "    \n",
    "    chunk_size=128\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "#call download and unzip\n",
    "def DownloadHourData_BAST(CounterNumber, year, FolderSave):\n",
    "\n",
    "    BAST_Link = 'https://www.bast.de/videos/' + str(year) + '/zst' + str(CounterNumber) + '.zip'\n",
    "    FileName = FolderSave + 'zst' + str(CounterNumber) + '_' + str(year) + '.zip'\n",
    "\n",
    "    #download zip\n",
    "    download_url(BAST_Link, FileName)\n",
    "    \n",
    "    #unzip file if downloading was successfull\n",
    "    try:\n",
    "        zf = ZipFile(FileName, 'r')\n",
    "        zf.extractall(FolderSave)\n",
    "        zf.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #remove zip file\n",
    "    os.system('rm ' + FileName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process one counting station in one year\n",
    "Reads and processes the downloaded BAST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_Year_And_CountingStation(path, DZ_Nr, year):\n",
    "    #read file\n",
    "    df = pd.read_csv(path, delimiter=';') \n",
    "\n",
    "    #reduce to important columns\n",
    "    var = ['Datum', 'Stunde', 'KFZ_R1', 'KFZ_R2']\n",
    "    df = df[var]\n",
    "\n",
    "    #change date information so pandas can read it\n",
    "    if year < 2010:\n",
    "        df['date'] = '200' + df['Datum'].astype(str)\n",
    "    else:\n",
    "        df['date'] = '20' + df['Datum'].astype(str)\n",
    "        \n",
    "    #add both counting directions\n",
    "    df['KFZ'] = df['KFZ_R1'] + df['KFZ_R2']\n",
    "    \n",
    "    #change date format to pandas datetime\n",
    "    df.date = pd.to_datetime(df.date, format='%Y%m%d')\n",
    "    \n",
    "    #reduce to date and KFZ and rename columns\n",
    "    df = df[['date', 'KFZ']]\n",
    "    df.rename(columns={'KFZ': str(DZ_Nr)},inplace=True)\n",
    "    \n",
    "    #reduce to daily data\n",
    "    df = df.groupby('date').sum()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process download request \n",
    "DZ_Nr_unique: Number of counting stations <br>\n",
    "years: years that should be downloaded <br>\n",
    "path: path to temp directory where the downloaded data is temporary stored <br>\n",
    "keepOrigData: Bool if downloaded raw data should be deleted: True: not deleted, False: deleted <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(DZ_Nr_unique, years, path, keepOrigData):\n",
    "\n",
    "    #sort years array ascending\n",
    "    years.sort()\n",
    "    print(years)\n",
    "    \n",
    "    #create temporary directory\n",
    "    if not os.path.exists(path):\n",
    "        os.system('mkdir ' + path)\n",
    "\n",
    "    #total number of counting stations that should be processed\n",
    "    total_count = len(DZ_Nr_unique)\n",
    "\n",
    "    #some prints\n",
    "    print('All counter stations: ', DZ_Nr_unique)\n",
    "    print('In total # = ', total_count)\n",
    "    count = 1\n",
    "    \n",
    "    #create empty dataframe for storing all data. \n",
    "    df_all = pd.DataFrame()\n",
    "    df_all['date'] = pd.date_range(start='1/1/'+str(years[0]),end='12/31/'+str(years[-1]))\n",
    "    df_all.index = df_all.date\n",
    "    df_all.index.name = \"date\" \n",
    "    df_all = df_all.drop(\"date\",axis=1)\n",
    "    \n",
    "    #loop over all counting stations\n",
    "    for nr in range(0,len(DZ_Nr_unique)):\n",
    "        \n",
    "        DZ_Nr = DZ_Nr_unique[nr]\n",
    "        print('Processing ' , count, ' of ', total_count)\n",
    "        count = count + 1\n",
    "        \n",
    "        #loop over years\n",
    "        for year in years:\n",
    "            \n",
    "            #filename in temp dir\n",
    "            f = 'zst' + str(DZ_Nr) + '_' + str(year) + '.csv'\n",
    "            try:\n",
    "                #download data\n",
    "                DownloadHourData_BAST(DZ_Nr, year, path)\n",
    "                #process downloaded data\n",
    "                df = Process_Year_And_CountingStation(path + f, DZ_Nr, year)\n",
    "                \n",
    "                #store data in dataframe for all data\n",
    "                if df.columns[0] in df_all.columns:\n",
    "                    df_all[df.columns[0]][df.index] = df[df.columns[0]]\n",
    "                else:\n",
    "                    df_all = pd.concat([df_all, df], axis=1)\n",
    "\n",
    "                #remove downloaded file if keepOrigData not True\n",
    "                if not keepOrigData:\n",
    "                    os.system('rm ' + path + f)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to download all available BAST data from the website\n",
    "keepOrigData: Bool if downloaded raw data should be deleted: True: not deleted, False: deleted <br>\n",
    "Uses \"Zeitreihen\" file from Zeitreihen_URL variable to get all Counting Station Numbers and years that are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadAllData(keepOrigData):\n",
    "\n",
    "    #download information of all available data\n",
    "    fileJahresdaten = 'Zeitreihe.csv'\n",
    "    Zeitreihen_URL = 'https://www.bast.de/BASt_2017/DE/Verkehrstechnik/Fachthemen/v2-verkehrszaehlung/Daten/2018_1/Jawe2018.csv?view=renderTcDataExportCSVAlleJahre&cms_strTyp=A'\n",
    "\n",
    "    #create temp dir if it does not exist\n",
    "    path = './temp/'\n",
    "    if not os.path.exists(path):\n",
    "        os.system('mkdir ' + path)\n",
    "\n",
    "    #download time series file\n",
    "    download_url(Zeitreihen_URL, path + fileJahresdaten)\n",
    "    df_Jahresdaten = pd.read_csv(path + fileJahresdaten, encoding='latin-1', delimiter=';') \n",
    "\n",
    "    #remove unused columns\n",
    "    var = ['DZ_Nr', 'Jahr']\n",
    "    df_Jahresdaten = df_Jahresdaten[var]\n",
    "\n",
    "    #create unique arrays for counting station numbers and years\n",
    "    DZ_Nr_unique = np.array(df_Jahresdaten.DZ_Nr.drop_duplicates())\n",
    "    years = np.array(df_Jahresdaten.Jahr.drop_duplicates(), 'int16')\n",
    "\n",
    "    #process these arrays\n",
    "    return Process(DZ_Nr_unique, years, path, keepOrigData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to download data that is given by the arrays\n",
    "DZ_Nr_arr: numpy array with counting station numbers that should be processes <br>\n",
    "years: numpy array withyears that should be processes <br>\n",
    "keepOrigData: Bool if downloaded raw data should be deleted: True: not deleted, False: deleted <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadPartOfData(DZ_Nr_arr, years, keepOrigData):\n",
    "    path = 'temp/'\n",
    "    return Process(DZ_Nr_arr, years, path, keepOrigData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to process daily data to monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessDailyToMonthly(filename):\n",
    "    df_daily = pd.read_csv(filename)\n",
    "    df_monthly = df_daily\n",
    "    df_monthly.date = pd.to_datetime(df_monthly.date).dt.to_period('m')\n",
    "    return df_monthly.groupby(\"date\").sum(min_count=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create one feature value from the data \n",
    "Because we do not want to have each counting station as a feature and also not all counting stations are available for the whole time the values of the counting stations are averaged to one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessToOneFeature(df_feat):\n",
    "    df_feat['M_BAST_AverTotalVehicPerCountingStation'] = df_feat.mean(axis=1, skipna=True)\n",
    "    return df_feat[['M_BAST_AverTotalVehicPerCountingStation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function that downloads all data and processes it to daily and monthly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #example for downloading only part of data\n",
    "    \"\"\"\n",
    "    DZ_Nr_arr = np.array([9140]) # counting station number\n",
    "    years = np.array([2007]) # year we are interesed in\n",
    "    keepOrigData = False # hourly data should be deleted\n",
    "    df_daily = DownloadPartOfData(DZ_Nr_arr, years, keepOrigData) \n",
    "    df_daily.to_csv('BAST_CountingStation_daily.csv')\n",
    "    \"\"\"\n",
    "    \n",
    "    #downloading all data\n",
    "    PathSave = ''\n",
    "    df_daily = DownloadAllData(keepOrigData)  \n",
    "    df_daily.to_csv('../data/mobility/raw_data/ZaehlstellenBAST/BAST_CountingStations_daily.csv')\n",
    "    \n",
    "    df_monthly = ProcessDailyToMonthly('../data/mobility/raw_data/ZaehlstellenBAST/BAST_CountingStations_daily.csv')\n",
    "    df_monthly.to_csv('../data/mobility/raw_data/ZaehlstellenBAST/BAST_CountingStations_monthly.csv')\n",
    "    \n",
    "    df_feat = ProcessToOneFeature(df_monthly)\n",
    "    df_feat.to_csv('../data/mobility/BAST_CountingStations_Feature_monthly.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
